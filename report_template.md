# CIFAR-10 图像分类实验报告

## 1. 实验概述

### 1.1 实验目标

本实验旨在使用深度学习方法对CIFAR-10数据集进行图像分类，具体目标包括：
- 设计并实现有效的CNN模型架构
- 掌握深度学习训练技巧（数据增强、正则化、学习率调度等）
- 对比不同模型架构的性能
- 分析模型的分类结果和误分类样本
- 探索模型优化和改进方向

### 1.2 数据集介绍

**CIFAR-10 数据集**是一个广泛使用的图像分类基准数据集，包含：

- **图像总数**: 60,000张32×32彩色图像
- **训练集**: 50,000张
- **测试集**: 10,000张
- **类别数**: 10个类别
- **类别名称**: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck

**数据集划分**:
- 训练集: 45,000张（90%）
- 验证集: 5,000张（10%）
- 测试集: 10,000张

## 2. 方法设计

### 2.1 模型架构

本实验实现了多种CNN架构，包括：

#### 2.1.1 自定义CNN (Custom CNN)

```
结构设计:
- 3个卷积块，每块包含2层卷积 + BatchNorm + MaxPooling
- 通道数递增: 64 → 128 → 256
- 3个全连接层: 4096 → 512 → 256 → 10
- 使用Dropout防止过拟合

参数量: ~3.7M
```

**设计思路**: 
- 逐层增加通道数以提取更复杂的特征
- 使用BatchNorm加速训练并提高稳定性
- Dropout防止过拟合

#### 2.1.2 ResNet-18

```
结构特点:
- 4个残差块组，每组2个残差块
- 残差连接解决梯度消失问题
- 适配CIFAR-10: 使用3×3卷积替代7×7，去除MaxPooling
- 全局平均池化 + 全连接层

参数量: ~11.2M
```

**优势**:
- 残差连接允许训练更深的网络
- 梯度流通更顺畅，训练更稳定
- 在小尺寸图像上表现优异

#### 2.1.3 VGG-16

```
结构特点:
- 5个卷积块，使用小卷积核（3×3）
- 通道数递增: 64 → 128 → 256 → 512
- 3个全连接层
- 精简版，适配CIFAR-10

参数量: ~14.7M
```

**特点**:
- 结构简单但有效
- 小卷积核堆叠增加网络深度
- 需要较大的计算资源

### 2.2 数据预处理与增强

#### 2.2.1 标准化

```python
# CIFAR-10统计值
mean = [0.4914, 0.4822, 0.4465]
std = [0.2023, 0.1994, 0.2010]

# 归一化到均值0，方差1
transforms.Normalize(mean, std)
```

#### 2.2.2 数据增强（训练集）

1. **随机裁剪 (Random Crop)**
   - 填充4像素后随机裁剪到32×32
   - 增加平移不变性

2. **随机水平翻转 (Random Horizontal Flip)**
   - 概率50%
   - 增加镜像对称性

3. **Cutout**
   - 随机遮挡16×16区域
   - 提高模型鲁棒性，防止过拟合

### 2.3 训练策略

#### 2.3.1 优化器

```python
SGD优化器:
- 学习率: 0.1
- 动量: 0.9
- 权重衰减: 5e-4
```

**选择理由**: SGD with Momentum在图像分类任务中表现稳定，配合适当的学习率调度能达到很好的效果。

#### 2.3.2 学习率调度

**Cosine Annealing**:
```python
lr_t = lr_0 × (1 + cos(πt/T)) / 2
```

**优势**:
- 平滑的学习率衰减
- 避免突然的学习率跳变
- 在训练末期仍保持一定的学习能力

#### 2.3.3 正则化技术

1. **Batch Normalization**
   - 加速训练收敛
   - 减少内部协变量偏移
   - 轻微的正则化效果

2. **Dropout (0.5)**
   - 在全连接层使用
   - 防止过拟合

3. **Weight Decay (5e-4)**
   - L2正则化
   - 限制权重大小

#### 2.3.4 早停机制

```python
Patience: 15 epochs
Min Delta: 0.001
```

在验证集准确率连续15个epoch没有提升时停止训练，防止过拟合。

### 2.4 评估指标

1. **准确率 (Accuracy)**: 整体分类准确率
2. **Top-K准确率**: Top-3, Top-5准确率
3. **每类准确率**: 各类别的单独准确率
4. **混淆矩阵**: 类别间混淆情况
5. **精确率、召回率、F1分数**: 详细的分类指标

## 3. 实验设置

### 3.1 硬件与软件环境

```
硬件:
- CPU: [待填写]
- GPU: [待填写]
- 内存: [待填写]

软件:
- Python: 3.8+
- PyTorch: 2.0+
- CUDA: [待填写]
- 操作系统: Linux/Windows
```

### 3.2 训练超参数

```python
主要超参数:
- Batch Size: 128
- Epochs: 100
- Initial Learning Rate: 0.1
- Optimizer: SGD (momentum=0.9, weight_decay=5e-4)
- LR Scheduler: Cosine Annealing
- Data Augmentation: Random Crop + Flip + Cutout
- Seed: 42 (保证可复现性)
```

## 4. 实验结果

### 4.1 训练过程

**[此处应包含训练曲线图]**

![训练曲线](results/training_curves.png)

**观察与分析**:
- 训练损失持续下降，表明模型在学习
- 验证损失先降后趋于平稳，无明显过拟合
- 训练准确率与验证准确率差距适中
- 学习率按照Cosine调度平滑衰减

### 4.2 测试集性能

#### 4.2.1 整体准确率

| 模型 | 参数量 | 测试准确率 | Top-3准确率 | Top-5准确率 |
|------|--------|-----------|------------|------------|
| Custom CNN | 3.7M | [待填写]% | [待填写]% | [待填写]% |
| ResNet-18 | 11.2M | [待填写]% | [待填写]% | [待填写]% |
| VGG-16 | 14.7M | [待填写]% | [待填写]% | [待填写]% |

**分析**:
- ResNet-18通常表现最佳，归功于残差连接
- 参数量并非决定性因素，架构设计更重要
- Top-5准确率显著高于Top-1，说明模型对大多数样本有正确的候选预测

#### 4.2.2 每类准确率

**[此处应包含每类准确率柱状图]**

![每类准确率](results/per_class_accuracy.png)

| 类别 | 准确率 | 正确数/总数 |
|------|--------|------------|
| airplane | [待填写]% | [待填写]/1000 |
| automobile | [待填写]% | [待填写]/1000 |
| bird | [待填写]% | [待填写]/1000 |
| cat | [待填写]% | [待填写]/1000 |
| deer | [待填写]% | [待填写]/1000 |
| dog | [待填写]% | [待填写]/1000 |
| frog | [待填写]% | [待填写]/1000 |
| horse | [待填写]% | [待填写]/1000 |
| ship | [待填写]% | [待填写]/1000 |
| truck | [待填写]% | [待填写]/1000 |

**观察**:
- 人造物体（airplane, automobile, ship, truck）准确率通常较高
- 动物类别（cat, dog, bird, deer）准确率相对较低
- 可能原因：动物类别内变化大，类间相似度高

### 4.3 混淆矩阵分析

**[此处应包含混淆矩阵图]**

![混淆矩阵](results/confusion_matrix.png)

**主要混淆对** (前10):

| 排名 | 真实类别 | 预测类别 | 数量 | 占比 |
|------|----------|----------|------|------|
| 1 | [待填写] | [待填写] | [待填写] | [待填写]% |
| 2 | [待填写] | [待填写] | [待填写] | [待填写]% |
| ... | ... | ... | ... | ... |

**分析**:
- Cat ↔ Dog 混淆最严重，两者外观相似
- Bird ↔ Deer 也有混淆，可能是背景颜色相似
- Automobile ↔ Truck 有轻微混淆，都是车辆

### 4.4 误分类样本分析

**[此处应包含误分类样本图]**

![误分类样本](results/misclassified_samples.png)

**典型误分类案例**:

1. **高置信度错误预测**:
   - 样本特征不明显或遮挡
   - 图像质量差或模糊
   - 罕见角度或姿态

2. **合理的混淆**:
   - Cat ↔ Dog: 体型、毛发颜色相似
   - Bird ↔ Airplane: 都在天空背景
   - Automobile ↔ Truck: 都是四轮车辆

3. **不合理的错误**:
   - 完全不相关的类别混淆
   - 可能是训练不足或模型容量问题

## 5. 讨论与分析

### 5.1 模型性能对比

**ResNet-18 vs Custom CNN**:
- ResNet-18准确率更高，归功于残差连接
- 训练更稳定，收敛更快
- 但参数量更大，推理时间略长

**VGG-16 vs ResNet-18**:
- VGG结构简单但参数量大
- ResNet更高效，性能更好
- VGG需要更多训练时间

### 5.2 数据增强的作用

**消融实验** (如果进行):

| 配置 | 测试准确率 | 说明 |
|------|-----------|------|
| 无增强 | [待填写]% | 基准 |
| + Random Crop/Flip | [待填写]% | 基础增强 |
| + Cutout | [待填写]% | 完整增强 |

**结论**: 数据增强显著提升模型泛化能力，Cutout对防止过拟合特别有效。

### 5.3 学习率调度的影响

Cosine Annealing的优势:
- 平滑的学习率衰减
- 训练末期仍能微调
- 相比StepLR，避免突然的性能波动

### 5.4 难分类类别分析

**Cat类别准确率低的原因**:
1. 猫的姿态变化大（坐、卧、站）
2. 毛色多样（黑、白、花）
3. 与狗外观相似（耳朵、四肢）
4. 背景复杂

**改进建议**:
- 增加针对性的数据增强
- 使用注意力机制关注关键特征（耳朵、脸部）
- 考虑使用对比学习增强类间区分度

### 5.5 易混淆类别对

**Cat-Dog混淆**:
- 相似特征：四肢动物、毛发、体型
- 区分点：耳朵形状、脸部特征
- 改进：增强面部特征的注意力

**Bird-Airplane混淆**:
- 相似特征：天空背景、飞行姿态
- 区分点：形状、材质
- 改进：背景抑制，关注主体形状

## 6. 改进方向与未来工作

### 6.1 模型架构改进

1. **注意力机制**
   - SENet: 通道注意力
   - CBAM: 通道+空间注意力
   - Self-Attention: 全局信息整合

2. **更先进的架构**
   - EfficientNet: 更优的深度-宽度-分辨率平衡
   - Vision Transformer: 自注意力机制
   - MobileNet: 轻量级高效网络

3. **集成学习**
   - 多模型投票
   - 模型融合
   - 知识蒸馏

### 6.2 训练技巧优化

1. **高级数据增强**
   - AutoAugment: 自动搜索增强策略
   - RandAugment: 随机增强
   - MixUp / CutMix: 样本混合

2. **损失函数改进**
   - Focal Loss: 关注难样本
   - Label Smoothing: 防止过拟合
   - 对比学习损失: 增强特征区分度

3. **优化器**
   - AdamW: 改进的权重衰减
   - RAdam: 自适应预热
   - Lookahead: 前瞻优化

### 6.3 实验扩展

1. **对比实验**
   - 不同初始化方法
   - 不同优化器
   - 不同学习率调度

2. **可解释性分析**
   - Grad-CAM: 可视化注意力区域
   - 特征图可视化
   - t-SNE: 特征空间分布

3. **迁移学习**
   - 使用ImageNet预训练
   - 微调策略对比
   - 域适应技术

## 7. 结论

### 7.1 主要成果

1. 成功实现了多种CNN架构在CIFAR-10上的分类
2. ResNet-18取得了最佳性能，准确率达到 [待填写]%
3. 数据增强和正则化显著提升了模型泛化能力
4. 详细分析了模型的优缺点和改进方向

### 7.2 经验总结

1. **模型选择**: 架构设计比参数量更重要
2. **数据增强**: 对小规模数据集特别重要
3. **学习率调度**: 直接影响最终性能
4. **早停机制**: 防止过拟合的有效手段
5. **误差分析**: 指导模型改进的重要方法

### 7.3 局限性

1. CIFAR-10图像分辨率低（32×32），限制了特征提取
2. 某些类别（如cat-dog）本质上难以区分
3. 模型在某些罕见情况下表现不佳
4. 计算资源限制了更大模型和更多实验的探索

### 7.4 展望

深度学习在图像分类领域仍有巨大的发展空间：
- 更高效的模型架构
- 更强大的数据增强技术
- 更好的优化算法
- 更强的可解释性

本实验为后续研究奠定了良好的基础。

## 8. 参考文献

1. Krizhevsky, A., & Hinton, G. (2009). Learning multiple layers of features from tiny images.
2. He, K., et al. (2016). Deep Residual Learning for Image Recognition. CVPR.
3. Simonyan, K., & Zisserman, A. (2015). Very Deep Convolutional Networks for Large-Scale Image Recognition. ICLR.
4. DeVries, T., & Taylor, G. W. (2017). Improved Regularization of Convolutional Neural Networks with Cutout. arXiv.
5. Loshchilov, I., & Hutter, F. (2017). SGDR: Stochastic Gradient Descent with Warm Restarts. ICLR.

## 附录

### 附录A: 代码结构

详见项目README.md

### 附录B: 完整实验配置

```python
# config.py中的完整配置
详见配置文件
```

### 附录C: 运行说明

详见README.md的使用方法部分

---

**实验日期**: [待填写]  
**实验人员**: [待填写]  
**实验地点**: [待填写]
