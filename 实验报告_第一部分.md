# Modern AI Tech - Project 3

### 陈子谦 10235501454

## 一、数据集与预处理

> 图像分类作为计算机视觉领域的基础任务，一直是深度学习研究的重要方向。本实验的主要目标是构建一个高性能的图像分类系统，通过系统性的实验设计和性能优化，探索深度卷积神经网络在小尺寸图像分类任务中的潜力。
>

### 1.1 数据集概述

​	CIFAR-10数据集由加拿大高等研究院（Canadian Institute for Advanced Research）发布，包含训练集**50,000张图像和测试集10,000张图像**，图像尺寸为32×32像素。为了更好地进行模型训练和超参数调优，在本实验中将原始训练集按照 `9:1` 的比例进一步划分为训练集（45,000张图像）和验证集（5,000张图像）。训练集用于模型参数的学习，验证集用于超参数调整和早停策略的判断，而测试集则严格保留用于最终的模型性能评估。

### 1.2 数据预处理与增强

​	数据预处理是深度学习训练流程中的关键环节，合理的预处理策略能够显著提升模型的泛化能力。本实验采用了多层次的数据预处理和增强方案，针对训练集和测试集分别设计了不同的处理流程。

​	对于训练集，实验采用了包含多种数据增强技术的预处理流程。首先，应用 Random Crop 操作，先对32×32的图像进行**4个像素**的边缘填充，然后随机裁剪回32×32的尺寸。这种操作通过模拟图像的轻微平移增强模型对位置变化的鲁棒性。其次，以50%的概率对图像进行水平翻转，这对于提升模型对左右对称物体的识别能力具有重要作用。

​	在数据归一化方面，实验采用了CIFAR-10数据集的标准统计参数。每个通道的均值分别为(0.4914, 0.4822, 0.4465)，标准差为(0.2023, 0.1994, 0.2010)。通过零均值归一化，可以加速模型收敛并提升训练稳定性。此外，实验还引入了Cutout数据增强技术，在图像中随机遮挡一个16×16像素的矩形区域**（在尝试了4x4, 8x8, 16x16等多种方案后，最终选定16x16为效果最好的一个）**

​	而对于验证集和测试集，考虑到评估需要保持数据的原始分布特征，仅进行张量转换和标准归一化操作，不应用任何随机性的数据增强。

### 1.3 数据加载策略

​	实验采用PyTorch框架的DataLoader进行高效的数据加载。batch-size设定为128，在计算效率和模型收敛速度之间取得了良好的平衡。为了充分打乱训练数据并提升模型的泛化能力，训练集在每个epoch开始时都会进行随机打乱（shuffle=True）。同时为了充分利用多核CPU资源加速数据加载，设置了8个工作进程并启用了内存固定（pin_memory=True），显著减少了数据加载的等待时间，提升了GPU的利用率。

​	验证集和测试集的批次大小设置为100，由于评估过程不需要反向传播，较大的批次可以加速推理过程。同时评估时关闭了数据打乱，确保每次评估的结果具有可重复性。

## 二、模型选择

**修改意见：此处需要并列对比Resnet18 、50、 VGG16 、Wide ResNet、DLA的区别，最终的选择是wide resnet**
